---
title: "PML_Final_Project"
author: "Viswathish Dinesh"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

This project aims to use accelerometer data to predict the class of exercise performed. The training and test data have been provided, with the training data containing the "classe" variable, which is what needs to be predicted in the test dataset.

# Pre Analysis

Before any analysis can begin, we need to complete some cursory steps to get our environment and our data ready.

## Load Libraries

The following package must be loaded for this analysis to create and test the model fit we will train on the training data.

```{r libraries, include=FALSE}
## Output has been muted to prevent unnecessary text
library(caret)
```

## Load Data

The data will be loaded into R. The training data can be found [here](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv). The test data can be found [here](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv). This data was downloaded on August 25, 2025.

```{r import data, cache = TRUE}
training <- read.csv("data/pml-training.csv")
testing <- read.csv("data/pml-testing.csv")
```

## Data Cleaning

```{r data cleaning}
## Remove features with near-zero variance
NZV <- nearZeroVar(training)

training <- training[,-NZV]
testing <- testing[,-NZV]

## Remove features not contributing to accelerometer readings

col_rm <- grepl("^X|timestamp|user_name", names(training))
training <- training[, !col_rm]
testing <- testing[, !col_rm]

## Remove columns with a majority of missing values

na_cols <- sapply(training, function(x) mean(is.na(x))) > 0.95
training <- training[,!na_cols]
testing <- testing[,!na_cols]

## Set "classe" feature as factor
training$classe <- factor(training$classe)
```

# Creating the model

## Split the data into training and validation sets

```{r training v validation}
set.seed(12345) # Set seed for reproducibility
inTrain <- createDataPartition(training$classe, p = 0.70, list = FALSE)
train_data <- training[inTrain,]
valid_data <- training[-inTrain,]
```

## Create the model on the training data

The model will be created using the random forest method.

```{r model creation, cache=TRUE}
set.seed(12345) ## Set seed for reproducibility
## Add training method for cross validation
train_control <- trainControl(method = "cv", number = 5)
modelFit <- train(classe ~ ., data = train_data, method = "rf", ntree = 250, trControl = train_control)
```

## Test the model on the validation data

```{r validation, cache = TRUE}
set.seed(12345) ## Set seed for reproducibility
## Predicting values using model
predictValid <- predict(modelFit, newdata = valid_data)
## Testing accuracy of model
con_matrix <- confusionMatrix(predictValid, valid_data$classe)
con_matrix
```

The accuracy of this model on the validation data is `r con_matrix$overall[1]`. The estimated out-of-sample error is `r 1-con_matrix$overall[1]`.

# Predicting outcomes of testing data

```{r model on test data, cache=TRUE}
set.seed(12345) ## Set seed for reproducibility
## Predict values using model
predictTest <- predict(modelFit, newdata = testing)
predictTest
```

The actual values of the "classe" outcome for the testing data can be found in the "Course Project Prediction Quiz". After entering the predicted value for each test case into the quiz, the outcome showed that the model predicted 100% of the values correctly.